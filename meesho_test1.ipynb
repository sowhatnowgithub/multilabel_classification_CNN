{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpXRETmcAHdA"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c visual-taxonomy"
      ],
      "metadata": {
        "id": "BQUDhz49AcaL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eccc9a82-c244-4677-bca8-534809e1dbc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "visual-taxonomy.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"\"\"\n",
        "import zipfile\n",
        "with zipfile.ZipFile('visual-taxonomy.zip','r') as zip_ref:\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n",
        "# \"\"\""
      ],
      "metadata": {
        "id": "NwVKcO7MAeqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gc"
      ],
      "metadata": {
        "id": "e4dLBTxvAeti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_df_train(idx):\n",
        "  df = pd.read_csv('train.csv')\n",
        "  df_idx = df[df['Category']==categories[idx]]\n",
        "  del df\n",
        "  gc.collect()\n",
        "  return df_idx"
      ],
      "metadata": {
        "id": "2s-KJVPQyd-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['Men Tshirts', 'Sarees' ,'Kurtis' ,'Women Tshirts' ,'Women Tops & Tunics']\n",
        "print(categories)"
      ],
      "metadata": {
        "id": "6UF5mUXrBKMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6220ce69-8644-4746-e8f4-b6a114f1911d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Men Tshirts', 'Sarees', 'Kurtis', 'Women Tshirts', 'Women Tops & Tunics']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_idx = load_df_train(1)"
      ],
      "metadata": {
        "id": "EXruxEKlDCpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories_consider = ['attr_2','attr_4','attr_5','attr_7','attr_9']"
      ],
      "metadata": {
        "id": "EEWLNNF4F84o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_attrs = []\n",
        "for i in range(len(categories_consider)):\n",
        "  df_attrs.append(df_idx[['id',categories_consider[i]]])\n",
        "# print(df_shirt_attr1.head())"
      ],
      "metadata": {
        "id": "_H_AGbCwD7pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(df_shirt_attr1.isnull().mean())\n",
        "filtered_df_idx = []\n",
        "for i,attr in enumerate(categories_consider):\n",
        "  df_attr = df_attrs[i]\n",
        "  filtered_df = df_attr[df_attr[attr].notnull()]\n",
        "  filtered_df_idx.append(filtered_df)"
      ],
      "metadata": {
        "id": "a1lLrNzDGJkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_attr_class = []\n",
        "unique_attr_class_len = []\n",
        "for i,attr in enumerate(categories_consider):\n",
        "  unique_attrs = filtered_df_idx[i][attr].unique().tolist()\n",
        "  unique_attr_class.append(unique_attrs)\n",
        "  unique_attr_class_len.append(len(unique_attrs))\n",
        "  print(f' {attr} unique attributes {unique_attr_class[i]} and lenght is {len(filtered_df_idx[i][attr].unique())}')"
      ],
      "metadata": {
        "id": "kxhUmy5UGxjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2137fc57-720f-4919-f8bc-5d66f3e8b93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " attr_2 unique attributes ['woven design', 'zari', 'no border', 'solid', 'default', 'temple border'] and lenght is 6\n",
            " attr_4 unique attributes ['multicolor', 'cream', 'white', 'default', 'navy blue', 'yellow', 'green', 'pink'] and lenght is 8\n",
            " attr_5 unique attributes ['party', 'traditional', 'daily', 'wedding'] and lenght is 4\n",
            " attr_7 unique attributes ['woven design', 'same as saree', 'default', 'zari woven'] and lenght is 4\n",
            " attr_9 unique attributes ['applique', 'elephant', 'floral', 'ethnic motif', 'peacock', 'default', 'solid', 'checked', 'botanical'] and lenght is 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "EXXbZyP3K-TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "y_attrs = []\n",
        "for i,attr in enumerate(categories_consider):\n",
        "  encoder = OrdinalEncoder(categories=[unique_attr_class[i]])\n",
        "  y = filtered_df_idx[i]\n",
        "  y = encoder.fit_transform(y[[attr]])\n",
        "  y = np.array(y)\n",
        "  y_attrs.append(y)"
      ],
      "metadata": {
        "id": "8fCogwbJICWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "0FfPvqYTLEeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(paths,n_images = 100, size=(128,128)):\n",
        "  images = []\n",
        "  for i,path in enumerate(paths):\n",
        "    if i == n_images:\n",
        "      break\n",
        "    image = tf.keras.preprocessing.image.load_img(path,target_size=size)\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = image/255.0\n",
        "    images.append(image)\n",
        "  return np.array(images)"
      ],
      "metadata": {
        "id": "oA9UduwLIhzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "hm0i4ORhNCuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_paths = os.listdir('train_images')\n",
        "img_paths = [os.path.join('train_images',path) for path in img_paths]\n",
        "img_paths.sort()"
      ],
      "metadata": {
        "id": "zWYRs7e7Mt14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "0Rty6uudOPBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "def get_size(data):\n",
        "  size = sys.getsizeof(data)\n",
        "  print(f'The size in GB is {size/1024**3}')"
      ],
      "metadata": {
        "id": "y9Lz_CQTOXxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_no_null = []\n",
        "for i in range(len(categories_consider)):\n",
        "  no_null = np.array(filtered_df_idx[i]['id'])\n",
        "  id_no_null.append(no_null)"
      ],
      "metadata": {
        "id": "w7Vztb_nOZOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_img_paths = []\n",
        "for j in range(len(categories_consider)):\n",
        "  filtered_img_path = [img_paths[i] for i in id_no_null[j]]\n",
        "  filtered_img_paths.append(filtered_img_path)"
      ],
      "metadata": {
        "id": "w1cpeTP3P738"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "a_wCZzAvRef9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_image(np_image):\n",
        "    image = Image.fromarray((np_image * 255).astype(np.uint8))\n",
        "    original_size = image.size\n",
        "\n",
        "    transform = T.Compose([\n",
        "        T.RandomHorizontalFlip(p=0.5),\n",
        "        T.RandomVerticalFlip(p=0.5),\n",
        "        T.RandomRotation(degrees=10),\n",
        "        T.ColorJitter(brightness=0.1,\n",
        "                      contrast=0.1,\n",
        "                      saturation=0.05,\n",
        "                      hue=0.02),\n",
        "        T.CenterCrop(size=original_size)\n",
        "\n",
        "    ])\n",
        "    augmented_image = transform(image)\n",
        "    augmented_np_image = np.array(augmented_image)\n",
        "    return augmented_np_image\n",
        "def generate_aument_images(np_images):\n",
        "  augmented_images = []\n",
        "  for i in range(len(np_images)):\n",
        "    augmented_image = augment_image(np_images[i])\n",
        "    augmented_image = augmented_image/255.0\n",
        "    augmented_images.append(augmented_image)\n",
        "  return np.array(augmented_images)"
      ],
      "metadata": {
        "id": "R67qVtxOPUks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img = load_images(filtered_img_paths[0])\n",
        "# aug_img = generate_aument_images(img)"
      ],
      "metadata": {
        "id": "XYmu_cZUSpja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "KRI2X1bkSqQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(n_classes,input_shape, each_class_attr):\n",
        "  input_layer = Input(shape=input_shape)\n",
        "\n",
        "  x = Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
        "  x = MaxPooling2D((2, 2))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "\n",
        "  x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "\n",
        "  x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  x = Dense(128, activation='relu')(x)\n",
        "  x = Dropout(0.5)(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "\n",
        "  output_layers = []\n",
        "  loss_functions = {}\n",
        "  metrics = {}\n",
        "  for i in range(n_classes):\n",
        "    output_name = f'attr{i+1}_output'\n",
        "    y = Dense(each_class_attr[i], activation='softmax', name=output_name)(x)\n",
        "    loss_functions[output_name] = 'sparse_categorical_crossentropy'\n",
        "    metrics[output_name] = 'accuracy'\n",
        "    output_layers.append(y)\n",
        "  model = Model(inputs=input_layer, outputs=output_layers)\n",
        "  opt = Adam(0.0002)\n",
        "  model.compile(optimizer=opt, loss=loss_functions, metrics=metrics)\n",
        "  return model\n",
        "\n"
      ],
      "metadata": {
        "id": "QD4PWT_QR5yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fiW2k3ApA4dB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saree_attr7 = define_model(n_classes=1, input_shape=(128,128,3), each_class_attr=[4])"
      ],
      "metadata": {
        "id": "nlfiRi1qS7Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saree_attr7.summary()"
      ],
      "metadata": {
        "id": "nmXvtb0bS7Wu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "outputId": "6fdef367-8ec8-485b-ce69-c1bdb5f82465"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_12               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_13               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_14               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m445568\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m57,032,832\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_15               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attr1_output (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m516\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_12               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_13               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_14               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">445568</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">57,032,832</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_15               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ attr1_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m57,128,004\u001b[0m (217.93 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,128,004</span> (217.93 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m57,127,300\u001b[0m (217.92 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">57,127,300</span> (217.92 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(x_train, y_train,x_val,y_val, model, batch_size=64, epochs=10):\n",
        "  model.fit(x_train, y_train, validation_data=(x_val,y_val),batch_size=batch_size, epochs=epochs)"
      ],
      "metadata": {
        "id": "byIFMHgAxuah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def del_and_load_images(idx,x_train,x_val,y_train,y_val):\n",
        "  del x_train, x_val, y_train, y_val,\n",
        "  gc.collect()\n",
        "  y = y_attrs[idx]\n",
        "  x = load_images(filtered_img_paths[idx], n_images=len(y), size=(128,128))\n",
        "  x_train, x_val, y_train, y_val = train_test_div(x,y)\n",
        "  del x,y\n",
        "  gc.collect()\n",
        "  return x_train, x_val, y_train, y_val"
      ],
      "metadata": {
        "id": "tKIsWeTZzjlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "def train_test_div(x,y):\n",
        "  x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "  return x_train, x_val, y_train, y_val"
      ],
      "metadata": {
        "id": "PjfDKacZ2FUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_val,y_train,y_val = del_and_load_images(3,0,0,0,0)"
      ],
      "metadata": {
        "id": "wAcPPrwO1u0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(x_train,y_train,x_val,y_val,saree_attr7,epochs=10)\n"
      ],
      "metadata": {
        "id": "qB3sZo25vuLx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f34a71-5149-4b02-a79e-b4ea1eadd1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 191ms/step - accuracy: 0.2414 - loss: 0.0000e+00 - val_accuracy: 0.2185 - val_loss: 0.0000e+00\n",
            "Epoch 2/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.2417 - loss: 0.0000e+00 - val_accuracy: 0.2185 - val_loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 72ms/step - accuracy: 0.2441 - loss: 0.0000e+00 - val_accuracy: 0.2185 - val_loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 74ms/step - accuracy: 0.2317 - loss: 0.0000e+00 - val_accuracy: 0.2185 - val_loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - accuracy: 0.2440 - loss: 0.0000e+00 - val_accuracy: 0.2185 - val_loss: 0.0000e+00\n",
            "Epoch 6/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.2468 - loss: 0.0000e+00 - val_accuracy: 0.2185 - val_loss: 0.0000e+00\n",
            "Epoch 7/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 76ms/step - accuracy: 0.2383 - loss: 0.0000e+00 - val_accuracy: 0.2185 - val_loss: 0.0000e+00\n",
            "Epoch 8/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 74ms/step - accuracy: 0.2436 - loss: 0.0000e+00 - val_accuracy: 0.2185 - val_loss: 0.0000e+00\n",
            "Epoch 9/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 76ms/step - accuracy: 0.2428 - loss: 0.0000e+00 - val_accuracy: 0.2185 - val_loss: 0.0000e+00\n",
            "Epoch 10/10\n",
            "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - accuracy: 0.2377 - loss: 0.0000e+00 - val_accuracy: 0.2185 - val_loss: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del x_train,x_val,y_train,y_val, filtered_df, filtered_df_idx, df_idx, df_attrs, filtered_img_paths, img_paths, unique_attr_class, unique_attr_class_len, id_no_null, y_attrs\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh-_GR7_1yGX",
        "outputId": "5f65b886-e462-4c2a-eee9-6c2509437568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1026"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aug_images = generate_aument_images(x_train[0:4500])"
      ],
      "metadata": {
        "id": "AMjaWkIK1ynj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train1 = x_train[0:4500]"
      ],
      "metadata": {
        "id": "ghT6xfup3IJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del x_train"
      ],
      "metadata": {
        "id": "S93UYhiY6qsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.concatenate((x_train1,aug_images),axis=0)"
      ],
      "metadata": {
        "id": "0KmlDlcI4NtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train1 = y_train[0:4500]"
      ],
      "metadata": {
        "id": "WjhKQ08p6BxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_aug = y_train[0:4500]"
      ],
      "metadata": {
        "id": "FRkr5kLt6Jqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del y_train"
      ],
      "metadata": {
        "id": "7nhSBot76ttE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.concatenate((y_train1,y_aug), axis=0)"
      ],
      "metadata": {
        "id": "1tnO09n_6NaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del aug_images, y_aug, y_train1, x_train1"
      ],
      "metadata": {
        "id": "wnAYU8Ge6v7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz9vHQA66Ziq",
        "outputId": "79662d8a-5843-409a-e16f-9278ac7a7861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "748"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(x_train,y_train,x_val,y_val,saree_attr7,epochs=10)"
      ],
      "metadata": {
        "id": "G_SrgGS85y_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9Tr_oii7mQS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}